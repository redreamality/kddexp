\section{Related Works}
\label{sec:rel}
%improves: incrementally training the entity-concepts so that it can model time varying attributes.(phone,manufacturer,company)--after2007-->(smartphone ï¼Œmanufacturer,company)
%perform NER~\cite in the document to link the entities.
%\subsection{Relation Explanation}

Our work is closely related to the following two lines of existing efforts: relation explanation and relation extraction.

In \emph{relation explanation}, given the SPO triple of entity pairs and relationship in the knowledge graph, the goal is to retrieve text describing such relationship.
Blanco et al.~\cite{blanco2010finding} study the problem of finding support sentences to explain the relationship between a named entity and an ad-hoc query.
Fang et al.~\cite{fang2011rex} explain the relationship between 2 entities by answering a subgraph from the knowledge base.
Voskarides et al.~\cite{voskarideslearning} models the problem of explaining relationship between entities into sentences retrieval problem, ranking the explanation sentences from Wikipedia by how well it describes the relationship.
In contrast, we focus on entity pairs that do not have supporting SPO triples as input.

In \emph{relation extraction}, the goal is extracting SPO triples from text.
Early work~\cite{hearst1992automatic,brin1999extracting,agichtein2000snowball} and some wiki-based~\cite{ponzetto2008wikitaxonomy} approaches use hand-crafted patterns.
Supervised classification based works~\cite{doddington2004automatic,guodong2005exploring} are carried out on small labelled data while distant learning~\cite{craven1999constructing,wu2007autonomously,bunescu2007learning,mintz2009distant} do not require labelled data.
Recent effort~\cite{angeli2014combining} applied active learning and combines distant and partial supervision.
These efforts, including NELL, are based on fixed set of prespecified relations.
Another type of relation extraction is open relation extraction~\cite{banko2007open}, such as Reverb~\cite{fader2011identifying}, OLLIE~\cite{schmitz2012open}, which are unsupervised approaches extracting relations from plain text.
PATTY~\cite{nakashole2012patty} extract open relational patterns from Wikipedia and New York Times and organize them into a taxonomy.
Our approach is closely related to generative models, instead of the latent variables used in type-LDA model~\cite{yao2011structured}, we apply a probabilistic framework leveraging rich concepts.
Our work differs from relation extraction tasks since we are given an entity pair instead of a sentence as the input, which is more challenging.

%\subsection{Link Label Prediction}

%Link Label Prediction~\cite{agrawal2013link}

%\subsection{Information Extraction}
%
%Attribute acquisition methods
%Among domain-dependent approaches, we can mention approaches that focus on products. In this domain, attributes have been used to improve product search and recommendation [18, 22], but also to enable data mining [27]
%
%Attribute retrieval provides another granularity in Web
%search. This can interest communities that propose a more
%focused access to information or communities that envision
%aggregating pieces of information such as aggregated search
%[19, 15].


%\subsection{Link entities to Database}
%
%Linking entities to database, especially to Wikipedia, has been widely studied. Entity linking to Wikipedia~\cite{milne2008learning,mihalcea2007wikify,han2011collective} exploit Wikipedia as thesaurus and link web documents to it.
%In our work, instead of linking entities to the correspond one in KB, we extract the target entity~\cite{dalvi2011automatic} and explain the semantic relation of the entity towards target entity.


%\subsection{Short Text Conceptualization}
