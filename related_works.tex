\section{Related Works}
\label{sec:rel}
%improves: incrementally training the entity-concepts so that it can model time varying attributes.(phone,manufacturer,company)--after2007-->(smartphone ï¼Œmanufacturer,company)
%perform NER~\cite in the document to link the entities.
%\subsection{Relation Explanation}

Our work is closely related to the following two lines of existing efforts: relation explanation and relation extraction.


In \emph{relation explanation}, given the SPO triple of entity pairs and relationship in the knowledge graph, the goal is to retrieve text describing such relationship .
Blanco et al.~\cite{blanco2010finding} study the problem of finding support sentences to explain the relationship between a named entity and an ad-hoc query.
Fang et al.~\cite{fang2011rex} explain the relation ship between 2 entities by answering a subgraph from the knowledge base.
Voskarides et al.~\cite{voskarideslearning} models the problem of explaining relationship between entities into sentences retrieval problem, ranking the explanation sentence from Wikipedia by how well it describe the relationship.
In contrast, we focus on entity pairs without supporting SPO triples.
 

In \emph{relation extraction}, the goal is extracting SPO triples from text.
Early work~\cite{hearst1992automatic,brin1999extracting,agichtein2000snowball} and some wiki-based~\cite{ponzetto2008wikitaxonomy} approaches apply hand-crafted patterns.
Supervised classification~\cite{doddington2004automatic,guodong2005exploring} and distant learning~\cite{craven1999constructing,wu2007autonomously,bunescu2007learning,mintz2009distant}.
Recent effort~\cite{angeli2014combining} applied active learning and combines distant and partial supervision.
These efforts, including NELL, are based on  fixed set of prespecified relations.
Another type of relation extraction is open relation extraction~\cite{banko2007open}, such as Reverb~\cite{fader2011identifying}, OLLIE~\cite{schmitz2012open} are unsupervised approaches extracting relations from plain text.
PATTY~\cite{nakashole2012patty} also extract open relational patterns from wikipedia and organize them into a taxonomy.
In contrast to having a sentence as an input, we are given an entity pair as an input, which is more challenging.
Our approach is closely related to generative models of using rich concepts~\cite{yao2011structured}, instead of the latent variables used in type-LDA model,
though research question is different.



%\subsection{Link Label Prediction}

%Link Label Prediction~\cite{agrawal2013link}

%\subsection{Information Extraction}
%
%Attribute acquisition methods
%Among domain-dependent approaches, we can mention approaches that focus on products. In this domain, attributes have been used to improve product search and recommendation [18, 22], but also to enable data mining [27]
%
%Attribute retrieval provides another granularity in Web
%search. This can interest communities that propose a more
%focused access to information or communities that envision
%aggregating pieces of information such as aggregated search
%[19, 15].


%\subsection{Link entities to Database}
%
%Linking entities to database, especially to Wikipedia, has been widely studied. Entity linking to Wikipedia~\cite{milne2008learning,mihalcea2007wikify,han2011collective} exploit Wikipedia as thesaurus and link web documents to it.
%In our work, instead of linking entities to the correspond one in KB, we extract the target entity~\cite{dalvi2011automatic} and explain the semantic relation of the entity towards target entity.


%\subsection{Short Text Conceptualization}
