% !TEX root = main.tex
\section{Introduction}
%Semantifying the hyperlinks in web documents is a huge task.
Recent years have witnessed the booming of semi-structured documents, especially online encyclopedia such as  Wikipedia~\footnote{\small\url{http://www.wikipedia.org}}, which serves important roles in offering knowledge services.
{\it Wikipedia.org} is consistently among the top 10 most visited websites according to Alexa Traffic Ranks~\footnote{\small\url{http://www.alexa.com/siteinfo/http://www.wikipedia.org}}.
Wikipedia is flooded with hyperlinks, which interconnect the Wikipedia articles.
In general, one article contains a hyperlink to another article because the entities corresponding to the articles has a certain semantic relationship.
But unfortunately why the two articles are hyperlinked remains unknown.

\subsection{Problem Statement}
In this paper, we dedicated our effort to {\it semantifying the hyperlinks in Wikipedia}.
That is explicitly explaining the relationship between an entity pair whose corresponding Wikipedia articles are hyperlinked with each other.
For example in the Wikipedia page of \at{Adolf Hitler}, \at{World War II} hyperlinked as an entity in the sentence \at{... \underline{Hitler} was at the centre of \underline{World War II} in Europe ...} in the first paragraph.
%There are many other linked entities, most of which are hyperlinked however don't exist relation in knowledge bases such as DBpedia.
Since in Wikipedia, an article describes either an entity or a concept, we also use entities or concepts alternatively to refer to the articles in Wikipedia.

The semantified links is obviously helpful for the readership.
It is easier to understand the surrounding sentences given the explicit explanation of the relationship between an entity and its hyperlinked entity.
Various text processing tasks can also benefit from semantified hyperlinks.
%For machines, having the initial guess of the semantic relations can be potentially helpful.
The establishment of the semantic relationship between two entities can be regarded as an effort to build knowledge graphs.
The entities as well as their semantic relationships can be utilized as part of the answering graph in graph-based relation explanation tasks~\cite{fang2011rex}.
They also can be used as the input of explanation tasks~\cite{voskarideslearning} that returns natural language sentence as explanation.
In question answering systems~\cite{yang2014slq}, the semantified links will largely reduce the search space of the answers.
Say our query is \at{Who wrote \underline{Mocking Bird}?}, recognizing \at{Mocking Bird} is actually a song will prevent searches into non-related concept pairs such as \at{<film, director>} shared by the attribute, and lead to the correct entity \at{Eminem\_(artist)} faster.
This save search space dramatically when queries are complicated with multiple entities and relations.
Other NLP tasks such as semantic role labeling~\cite{palmer2010semantic}, selectional preference~\cite{pantel2007isp} and textual entailment~\cite{androutsopoulos2010survey} tasks under knowledge intensive circumstances~\cite{yao2012unsupervised,exner2011using}, knowing the semantic relationship between entities will make a difference in sense disambiguation.

\begin{figure}[!htb]
\centering
\epsfig{file=resources/df_for_plot_writer.eps,width=\columnwidth,height=0.618\columnwidth }
\caption{\scriptsize Concept pairs \at{\scriptsize <song,artist>}, \at{\scriptsize <film,director>} sharing the same attribute \at{ \scriptsize writer}.}
\label{fig:writer}
\end{figure}


\subsection{Our Core Idea}
A direct solution is using the attributes to explain the entity pairs.
Note that DBpedia contains many structured facts of entities or concepts.
For example, it has the SPO (subject-predicate-objec) triples \at{<Leonardo Da Vinci, ArtistOf, Mona Lisa>} which indicates the predicate \at{ArtistOf} (which is an attribute of \at{Leonardo Da Vinci}) can explain the relation between \at{Leonardo Da Vinci} and \at{Mona Lisa}.
However, using attribute as the explanation does not always work due to the sparsity of structured facts.
Our statistics reveal that there are \emph{968 millions} of unique links between Wikipedia entities, only \emph{15 millions} (1.5\%) of which can find semantic explanation from DBpedia.
%The types of hyperlink are article to article, article to knowledge base(or encyclopedia-like databases). Each link has two ends the original one(the web page/ entity page contains it) and the oriented one(the web page/ entity page it points to), and each end has 2 possible types, an anchor url or an anchor entity. Hence, in all there are 4 possible combinations, which consists the 4 type of links.
%An anchor entity can be named entities such as movies, products, people names, locations etc. In this case we explain the relation between the entity and the original article. As for an anchor url, an automatic target entity extraction process[2011] can be performed, and then it become another semantifying problem between entities.


%In this paper we focus on the problem of semantifying the first type of hyperlinks since other kinds of links can finally be deduced to this problem.
Thus, {\it how to improve the recall when the relationship facts are not covered by the knowledge base?}
A key observation is that the relationship is determined by the concept pairs. For example, \at{<Leonardo Da Vinci, Mona Lisa>} can be best explained by \at{ArtistOf} attribute, which essentially is determined by the concept pair \at{<artist, painting>}. Hence, we can first learn the concept-attribute-concept (CAC) pattern from the existing entity-attribute-entity (EAE) instances. Then, use the CAC patterns to infer the relationship between a new entity pair or an entity pair with unknown relationship.
For instance, from triples like \at{<Leonardo Da Vinci, ArtistOf, Mona Lisa>}, \at{<Salvador Dali, ArtistOf, The Persistence of Memory>}, we learned CAC pattern \at{<artist, ArtistOf, painting>}, which can be used to explain the \at{ArtistOf} relations between any artist and their paintings.

There are two perquisites of the above inference based approaches.
\begin{enumerate}
\item First, {\it we must map instances or entities to their concepts accurately}. Fortunately, many taxonomies about the entity-concept relationships such \ac{Probase} and \ac{WikiTaxonomy}) are available. These taxonomies allows us to conceptualize EAE instances into corresponding CAC patterns, as well as the deduction from the CAC to a specific EAE instance.
\item Second, {\it an enough number of relationship instances should be available to learn a CAC pattern of high trustworthy}. Fortunately, knowledge bases such as \ac{DBpeda} contains many such EAE instances. DBpedia covers more than one thousand of important relationships, which ensures the explanation of a wide range of relationships.
\end{enumerate}


%\ac{Probase} serves the purpose of retrieving entities' concepts and the corresponding typicality.
%\ac{DBpeda} is utilized as training data, from which we get EAE pairs.
%%For instance, after thousands of tuples like $$(Leonardo Da Vinci, ArtistOf, Mona Lisa)$$ are trained to learn the concept-concept space, a new pair of entity co-occurs, whose relation is not in the knowledge base, with the concept pair like \at{(artist, painting)}, will be with a high probability having the \at{ArtistOf} relation.
%We envision that the concept space plays an important role in attribute finding.
%For example, the relationship \at{ArtistOf} in \ac{DBpedia} will be correct in the tuple of {\tt(Leonardo Da Vinci, ArtistOf, Mona Lisa)} [{\tt("Human", ArtistOf, "Painting")}] and will be never correct in the tuple of {\tt ("Automobile", ArtistOf, Painting)} [e.g.{\tt(BMW i8, ArtistOf, Mona Lisa )}].
%Then we infer what kind of attributes would be likely to occur given a new entity pair.


\subsection{Challenges and Contributions}

In general, we need a learning framework to learn the CAC patterns form EAR instances.
This procedure can be regarded as a conceptualization procedure.
Two features distinguishing our learning procedure from previous conceptualization work of such learning are {\it collective conceptualization}, {\it joint conceptualization} and {\it head-aware conceptualization}.
Different from the previously conceptualization works, which in general use knowledge base to conceptualize a single world or phrase~\cite{song2011short,kim2013context}.
In our settings, we need to conceptualize the a set of EAE instances. It is rarely studied for collective conceptualization by knowledge base.
Second, an EAE instance like $<e_1, a, e_2>$, joint conceptualization of $e_1$ and $e_2$ are not independent, actually they are influential on each other. For example,,,.,\xch{what is needed here?}

\begin{example}[Joint conceptualization]
For example, given an entity pair \at{<apple, steve jobs>}. The candidate concepts for \at{apple} are \at{\{fruit,company,...\}} and the candidate concepts for \at{steve jobs} are \at{\{entrepreneur, pc developer,...\}}. Obviously, the concept pair \at{<fruit, entrepreneur>} is meaningless in this case.
\label{exa:jc}
\end{example}


\begin{example}[Collective conceptualization]
Continue the previous example, when we are further given \at{<microsoft, bill gates>}, \at{<ibm, thomas watson>}, who share the sam attribute \at{FoundBy} with \at{<apple, steve jobs>}, we can easily identify \at{<company,entrepreneur>} as a right concept pair, in that the new entity pairs has no opportunity to be conceptualized as \at{<fruit, entrepreneur>}.
\label{exa:sd}
\end{example}

\begin{example}[Head-aware conceptualization]
For example, the \at{FoundedBy} relationship between \at{Apple Inc.} and \at{Steve Jobs} are determined by the head concepts they possessed (e.g.\ \term{company} and \term{entrepreneur}, regardless of the modifiers such as \term{technology} in the concept \term{technology company}.)
\label{exa:hc}
\end{example}


%Challenges are as follows:
%\begin{description}
%  \item[C1] Entity Representation.
%  Finding the most plausible concept pairs for the entity pair is hard due to the sparsity of concepts.
%  The average number of parent concept~\cite{wu2012probase} for an entity is 1.04 in Yago and 2.33 in Probase.
%  Furthermore, an complete representation need to include probability information to reflect typicality rather than black-or-white assertion of the type.
%  \item[C2] Large search space.
%  Finding the most plausible relation for the concept pair distribution is time consuming due to the large concept pair space.
%  The exact inference requires to find maximal value from a C-C space that has over 4 trillion concepts' combination(probase has 2 million concepts )
%\end{description}



%We argue that the context of an entity in an article is informative[] and deserve a higher occurrence[] and can produce fresh and latest relation of an entity, which can be useful in updating the KB[reverb].

%In our approach the relations is not necessarily to be exist, however the cluster of the relation[relation clustering] it belongs to should be conceptually right. With rich context and large knowledge base, we can easily derive the fresh context relations and the concept of each entity,

%On the other hand, we consider the co-occurrence of the 2 entities, based on the assumption of important relationship will be observed in various of documents[]

For these reasons, we purpose a relation explanation method leveraging the concept and co-occurrence of and entity, to explain the relation between the target entity and the related entity, thus semantifying the hyperlink.
%To summarize, our paper has following contributions:
%\begin{itemize}
%  \item
%  \item 
%\end{itemize}

The rest of the paper is organized as follows.
\yh{FINAL WORK}
%Section~\ref{sec:rel}
%Section~\ref{sec:framework}
%Section~\ref{sec:conceptualization}
%Section~\ref{sec:fafa}

%We first survey the related works,
%
%then we present a detailed problem statement our framework for entity relation finding.
% describes how we do conceptualization to map entities into a concept-concept space.
% unfolds how we retrieve the most plausible relationship for the concept pair.
%We perform various of experiment in section~\ref{sec:exp} and conclude in section~\ref{sec:conclusion}.
